# Interactive Digital Avatar

## Overview

Integrate 2D/3D avatars with a backend LLM server to provide real-time,
intelligent responses to user queries through speech-based
conversational interfaces.

## Get Started

Explore the ["Get Started" guide](./docs/get-started.md) to learn how to:

- setup the [client](./docs/get-started.md#environment-setup-for-windows)
  and [server](./docs/get-started.md#environment-setup-for-ubuntu) machines,
- prepare and deploy:\
  [MuseTalk](./docs/get-started.md#musetalk) - a
  real-time high quality lip-syncing model and\
  [FunASR Paraformer-large](./docs/get-started.md#funasr)
  \- a non-autoregressive end-to-end speech recognition model,
- create a production-ready
  [Retrieval-Augmented Generation (RAG) pipeline](./docs/get-started.md#prepare-rag).

## Use cases

The article delves into the most fundamental [use cases](./docs/use-cases.md)
of integrating interactive [2D](./docs/use-cases.md#2d-avatar)/
[3D](./docs/use-cases.md#3d-avatar) avatars, including text or video chat.

## Claim

THIS PROJECT IS ARCHIVED

Intel will not provide or guarantee development of or support for this project, including but not limited to, maintenance, bug fixes, new releases or updates.

Patches to this project are no longer accepted by Intel.

If you have an ongoing need to use this project, are interested in independently developing it, or would like to maintain patches for the community, please create your own fork of the project.
